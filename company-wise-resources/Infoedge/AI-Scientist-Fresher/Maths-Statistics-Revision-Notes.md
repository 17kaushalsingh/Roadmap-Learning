# Maths & Statistics Revision - AI Scientist Interview Prep

## Table of Contents
1. [Probability](#probability)
2. [Probability Distributions](#probability-distributions)
3. [Sampling](#sampling)
4. [Correlations](#correlations)
5. [Hypothesis Testing](#hypothesis-testing)
6. [Statistical Significance](#statistical-significance)
7. [Central Limit Theorem](#central-limit-theorem)
8. [Paired Means Tests](#paired-means-tests)
9. [Bayes' Theorem](#bayes-theorem)
10. [Linear Algebra](#linear-algebra)

---

## Probability

### Key Concepts

**Basic Definitions:**
- **Probability**: P(A) = Number of favorable outcomes / Total possible outcomes
- **Conditional Probability**: P(A|B) = P(A ‚à© B) / P(B)
- **Independent Events**: P(A ‚à© B) = P(A) √ó P(B)

**Rules:**
- **Addition Rule**: P(A ‚à™ B) = P(A) + P(B) - P(A ‚à© B)
- **Multiplication Rule**: P(A ‚à© B) = P(A) √ó P(B|A)

### Interview Questions

#### Q1: Two fair coins are tossed. What's the probability of getting exactly one head?
**Intuition**: Count favorable outcomes vs total outcomes.

**Solution**: Total outcomes = 4 (HH, HT, TH, TT). Favorable = 2 (HT, TH)
P = 2/4 = 0.5

**Follow-up Questions**:
- What if we toss 3 coins? What's P(exactly 2 heads)?
- Generalize: For n coins, what's P(exactly k heads)?

#### Q2: In a bag with 3 red and 2 blue balls, what's P(2nd ball is red) given that 1st was blue?
**Solution**: After removing 1 blue: 3 red, 1 blue remain. P(2nd is red) = 3/4

**Follow-up**: What if balls are replaced? What if order matters?

#### Q3: A die is rolled twice. What's P(sum > 9)?
**Solution**: Total outcomes = 36. Favorable outcomes: (4,6), (5,5), (5,6), (6,4), (6,5), (6,6)
P = 6/36 = 1/6

**Real Interview Question**: "A card is drawn from a standard deck. What's the probability it's a heart given that it's a face card?"

---

## Probability Distributions

### Key Distributions

**1. Discrete Distributions:**
- **Bernoulli**: Single trial with P(success) = p, P(failure) = 1-p
- **Binomial**: n independent Bernoulli trials
  - P(X = k) = C(n,k) √ó p^k √ó (1-p)^(n-k)
- **Poisson**: Number of events in fixed interval
  - P(X = k) = (Œª^k √ó e^(-Œª)) / k!

**2. Continuous Distributions:**
- **Normal**: Mean Œº, variance œÉ¬≤
  - f(x) = (1/‚àö(2œÄœÉ¬≤)) √ó e^(-(x-Œº)¬≤/(2œÉ¬≤))
- **Exponential**: Time between events
  - f(x) = Œª √ó e^(-Œªx), x ‚â• 0

### Properties to Remember

| Distribution | Mean | Variance | Key Use Case |
|--------------|------|----------|-------------|
| Bernoulli | p | p(1-p) | Single success/failure |
| Binomial | np | np(1-p) | Fixed trials, success counting |
| Poisson | Œª | Œª | Rare event counting |
| Normal | Œº | œÉ¬≤ | Natural phenomena |
| Exponential | 1/Œª | 1/Œª¬≤ | Waiting times |

### Interview Questions

#### Q1: Calls to a call center follow Poisson with Œª=2/minute. What's P(no calls in 3 minutes)?
**Solution**: For 3 minutes: Œª' = 2√ó3 = 6
P(X=0) = (6^0 √ó e^(-6)) / 0! = e^(-6) ‚âà 0.00248

**Follow-up**: What's P(at least 2 calls)? What's expected calls in 10 minutes?

#### Q2: Heights follow N(170, 25) in cm. What % > 175cm?
**Solution**: Z = (175-170)/‚àö25 = 5/5 = 1
P(Z > 1) = 1 - 0.8413 = 0.1587 or 15.87%

**Real Interview Question**: "A manufacturing process has 2% defect rate. What's the probability of exactly 3 defects in a batch of 100 items?"

---

## Sampling

### Key Concepts

**Sampling Methods:**
```
Simple Random Sample (SRS)
‚îú‚îÄ‚îÄ Each unit has equal probability
‚îî‚îÄ‚îÄ Selection is independent

Stratified Sampling
‚îú‚îÄ‚îÄ Population divided into strata
‚îî‚îÄ‚îÄ Random sample from each stratum

Systematic Sampling
‚îú‚îÄ‚îÄ Select every kth unit
‚îî‚îÄ‚îÄ Random starting point
```

**Sample Statistics:**
- **Sample Mean**: xÃÑ = Œ£xi / n
- **Sample Variance**: s¬≤ = Œ£(xi - xÃÑ)¬≤ / (n-1)
- **Standard Error**: SE = œÉ/‚àön

### Interview Questions

#### Q1: Population mean = 50, œÉ = 10. Sample size = 25. What's standard error?
**Solution**: SE = œÉ/‚àön = 10/5 = 2

**Follow-up**: What's probability sample mean > 52? How does SE change with n=100?

#### Q2: Explain stratified sampling vs simple random sampling.
**Answer**: Stratified ensures representation of all subgroups, reduces variance, better for heterogeneous populations.

**Real Interview Question**: "You have a dataset of 1M users. How would you sample 10K for analysis while ensuring representation across age groups?"

---

## Correlations

### Key Concepts

**Correlation Coefficient (r):**
- Range: [-1, 1]
- r = 1: Perfect positive linear
- r = -1: Perfect negative linear
- r = 0: No linear correlation

**Formula**: r = Œ£((xi - xÃÑ)(yi - »≥)) / ‚àö(Œ£(xi - xÃÑ)¬≤ √ó Œ£(yi - »≥)¬≤)

**Correlation Types:**
```
Pearson: Linear relationships
Spearman: Monotonic relationships (rank-based)
Kendall: Ordinal associations
```

### Interview Questions

#### Q1: Data: x=[1,2,3,4,5], y=[2,4,5,4,5]. Calculate correlation.
**Solution**: xÃÑ=3, »≥=4, calculate using formula ‚Üí r ‚âà 0.7

**Follow-up**: What if we square all x-values? How does correlation change?

#### Q2: Can correlation = 0 for nonlinearly related variables?
**Answer**: Yes! Example: y = x¬≤ for x ‚àà [-2,2]. Strong nonlinear relationship but r = 0.

**Real Interview Question**: "You find correlation 0.8 between study hours and test scores. Can we conclude that more studying causes better scores?"

---

## Hypothesis Testing

### Key Concepts

**Hypothesis Structure:**
- **H‚ÇÄ (Null)**: No effect/difference
- **H‚ÇÅ (Alternative)**: Effect/difference exists

**Test Statistics:**
- **Z-test**: Population œÉ known, n ‚â• 30
- **t-test**: Population œÉ unknown, n < 30
- **Chi-square**: Categorical data

**Decision Rules:**
- **Reject H‚ÇÄ**: |test statistic| > critical value
- **p-value approach**: Reject H‚ÇÄ if p < Œ±

### Common Tests

| Test | Purpose | Assumptions |
|------|---------|-------------|
| One-sample t | Œº vs hypothesized value | Normality, œÉ unknown |
| Two-sample t | Œº‚ÇÅ vs Œº‚ÇÇ | Normality, equal variances |
| Paired t | Before/after | Paired data, normality |
| Chi-square | Goodness of fit | Expected frequencies ‚â• 5 |

### Interview Questions

#### Q1: H‚ÇÄ: Œº = 100, Œ± = 0.05, two-tailed. Sample: n=25, xÃÑ=105, s=10. Test hypothesis.
**Solution**: t = (105-100)/(10/‚àö25) = 5/2 = 2.5
Critical t(24, 0.025) = ¬±2.064. |2.5| > 2.064 ‚Üí Reject H‚ÇÄ

**Follow-up**: Calculate p-value. What if n=100? What's Type I/II error risk?

#### Q2: When to use t-test vs z-test?
**Answer**: t-test when œÉ unknown or n < 30, z-test when œÉ known and n ‚â• 30.

**Real Interview Question**: "A/B test shows conversion rates: Control=10%, Treatment=12%, n=1000 each. Is the difference significant at Œ±=0.05?"

---

## Statistical Significance

### Key Concepts

**p-value**: Probability of observing extreme results if H‚ÇÄ is true

**Significance Level (Œ±)**: Pre-determined threshold (usually 0.05)

**Decision Matrix:**
```
                Reality
                H‚ÇÄ True    H‚ÇÄ False
     Reject     Type I    Correct
     Not Reject Correct   Type II
```

**Effect Size**: Magnitude of difference, independent of sample size

### Common Œ± Levels and Interpretation

| p-value range | Interpretation |
|---------------|----------------|
| p > 0.05 | Not significant |
| 0.01 < p ‚â§ 0.05 | Significant |
| 0.001 < p ‚â§ 0.01 | Highly significant |
| p ‚â§ 0.001 | Very highly significant |

### Interview Questions

#### Q1: p = 0.03 vs Œ± = 0.01. What's the decision?
**Answer**: Do not reject H‚ÇÄ (0.03 > 0.01)

**Follow-up**: What if we change Œ± to 0.05? What's the risk of Type I error?

#### Q2: "Statistically significant but practically insignificant" - explain.
**Answer**: Large sample size can detect tiny differences that are statistically significant but have no practical importance.

**Real Interview Question**: "Your A/B test shows p=0.04 favoring version B. Should we automatically roll out version B?"

---

## Central Limit Theorem

### Key Concept

**CLT**: For any distribution with mean Œº and variance œÉ¬≤, the sampling distribution of xÃÑ approaches Normal(N(Œº, œÉ¬≤/n)) as n ‚Üí ‚àû

**Practical Rule**: For most distributions, CLT works well for n ‚â• 30

### Mathematical Foundation

```
Sample Mean Distribution:
Œº_xÃÑ = Œº (unbiased estimator)
œÉ_xÃÑ¬≤ = œÉ¬≤/n (variance decreases with n)

Standard Error: SE = œÉ/‚àön
```

### Interview Questions

#### Q1: Population: Exponential with mean=2. Sample size=50. What's distribution of sample mean?
**Answer**: Approximately Normal with Œº=2, œÉ¬≤/50 = 4/50 = 0.08

**Follow-up**: What's P(xÃÑ > 2.5)? How does this change with n=100?

#### Q2: Why is CLT important in statistics?
**Answer**: Enables inference about population parameters from sample statistics, forms basis for hypothesis testing and confidence intervals.

**Real Interview Question**: "You have a skewed income distribution. Why can we still use t-tests for means with large samples?"

---

## Paired Means Tests

### Key Concept

**Paired t-test**: Compares two related samples (before/after, matched pairs)

**Test Statistic**: t = (dÃÑ - Œº‚ÇÄ) / (sd/‚àön)

Where dÃÑ = mean of differences, sd = standard deviation of differences

### When to Use Paired Tests

```
‚úì Same subjects measured twice
‚úì Matched pairs (twins, matched groups)
‚úì Before-after experiments
‚úì Case-control studies
```

### Interview Questions

#### Q1: Weight before: [180,170,165], after: [175,168,160]. Test if weight loss significant.
**Solution**: Differences: [-5,-2,-5], dÃÑ = -4, sd = 1.73, n = 3
t = (-4-0)/(1.73/‚àö3) = -4.01. Critical t(2,0.05) = -2.92
|t| > |critical| ‚Üí Significant weight loss

**Follow-up**: Calculate 95% CI for mean difference. What assumptions are made?

#### Q2: Paired vs independent t-test - when to use which?
**Answer**: Paired for related measurements, independent for separate groups. Paired reduces variability by controlling for subject effects.

**Real Interview Question**: "You want to test if a new training program improves employee productivity. How would you design the study and which test would you use?"

---

## Bayes' Theorem

### Formula and Intuition

**Bayes' Theorem**: P(A|B) = P(B|A) √ó P(A) / P(B)

**Components**:
- **Prior**: P(A) - initial belief
- **Likelihood**: P(B|A) - probability of evidence given hypothesis
- **Posterior**: P(A|B) - updated belief after evidence

### Practical Form

```
P(A|B) = [P(B|A) √ó P(A)] / [P(B|A) √ó P(A) + P(B|A') √ó P(A')]
```

### Interview Questions

#### Q1: Disease prevalence = 1%, Test accuracy = 99%. Test positive. What's probability of having disease?
**Solution**:
P(Disease|+) = (0.99 √ó 0.01) / [(0.99 √ó 0.01) + (0.01 √ó 0.99)]
= 0.0099 / (0.0099 + 0.0099) = 0.5 = 50%

**Follow-up**: What if prevalence = 0.1%? What if test accuracy = 95%?

#### Q2: Two coins: one fair, one double-headed. Pick random coin, flip heads. What's probability it's double-headed?
**Solution**: P(Double|H) = (1 √ó 0.5) / [(1 √ó 0.5) + (0.5 √ó 0.5)] = 2/3

**Real Interview Question**: "Your ML model has 95% accuracy. In a population where 2% are fraud cases, a positive prediction occurs. What's the actual probability of fraud?"

---

## Linear Algebra

### Key Concepts

**Matrix Operations**:
- **Addition**: Element-wise
- **Multiplication**: (A√óB)·µ¢‚±º = Œ£(A·µ¢‚Çñ √ó B‚Çñ‚±º)
- **Inverse**: A‚Åª¬π such that A√óA‚Åª¬π = I
- **Transpose**: (A·µÄ)·µ¢‚±º = A‚±º·µ¢

**Eigenvalues and Eigenvectors**:
```
A √ó v = Œª √ó v
Where: v = eigenvector, Œª = eigenvalue
```

**Singular Value Decomposition (SVD)**:
```
A = U √ó Œ£ √ó V·µÄ
U: Left singular vectors (orthogonal)
Œ£: Singular values (diagonal)
V·µÄ: Right singular vectors (orthogonal)
```

### Applications in ML

| Concept | ML Application | Why Important |
|---------|----------------|----------------|
| Eigenvalues | PCA | Find principal components |
| SVD | Dimensionality reduction | Compress data efficiently |
| Matrix inverse | Linear regression | Solve normal equations |
| Matrix multiplication | Neural networks | Weight transformations |

### Interview Questions

#### Q1: Matrix A = [[2,1],[1,2]]. Find eigenvalues and eigenvectors.
**Solution**:
Characteristic equation: |A - ŒªI| = 0
(2-Œª)(2-Œª) - 1 = 0 ‚Üí Œª¬≤ - 4Œª + 3 = 0
Eigenvalues: Œª‚ÇÅ = 3, Œª‚ÇÇ = 1

For Œª=3: (A-3I)v = 0 ‚Üí [[-1,1],[1,-1]]v = 0 ‚Üí v‚ÇÅ = [1,1]
For Œª=1: (A-I)v = 0 ‚Üí [[1,1],[1,1]]v = 0 ‚Üí v‚ÇÇ = [1,-1]

**Follow-up**: What's the spectral decomposition? How does this relate to PCA?

#### Q2: Why is SVD important in machine learning?
**Answer**:
- Dimensionality reduction (keep top k singular values)
- Matrix completion/recommendation systems
- Numerical stability vs eigenvalue decomposition
- Works for any matrix (not just square)

**Real Interview Question**: "How would you use matrix decomposition to reduce the dimensionality of a user-item interaction matrix for recommendation?"

---

## Quick Reference Formulas

### Probability
- **Conditional**: P(A|B) = P(A‚à©B)/P(B)
- **Independence**: P(A‚à©B) = P(A)√óP(B)
- **Total Probability**: P(A) = Œ£P(A|B·µ¢)P(B·µ¢)

### Distributions
- **Binomial**: P(X=k) = C(n,k) √ó p·µè √ó (1-p)‚Åø‚Åª·µè
- **Poisson**: P(X=k) = Œª·µè √ó e‚ÅªŒª / k!
- **Normal**: f(x) = (1/‚àö(2œÄœÉ¬≤)) √ó e^(-(x-Œº)¬≤/(2œÉ¬≤))

### Statistics
- **Sample Mean**: xÃÑ = Œ£xi/n
- **Sample Variance**: s¬≤ = Œ£(xi-xÃÑ)¬≤/(n-1)
- **Correlation**: r = Œ£((xi-xÃÑ)(yi-»≥))/‚àö(Œ£(xi-xÃÑ)¬≤ √ó Œ£(yi-»≥)¬≤)
- **t-statistic**: t = (xÃÑ-Œº‚ÇÄ)/(s/‚àön)

### Matrix Operations
- **Matrix Multiplication**: (AB)·µ¢‚±º = Œ£‚Çñ A·µ¢‚ÇñB‚Çñ‚±º
- **SVD**: A = UŒ£V·µÄ
- **Eigenvalue**: det(A-ŒªI) = 0

---

## Practice Problems for Self-Assessment

### Set 1: Mixed Topics
1. Coin tossed until first head. Expected tosses? (Answer: 2)
2. Distribution of sample mean for n=36 from skewed population? (Answer: Approximately normal)
3. Correlation vs causation example from data science?

### Set 2: Advanced Applications
1. Naive Bayes classifier derivation from Bayes' theorem
2. PCA derivation using eigenvalue decomposition
3. Bootstrap method for confidence intervals

### Set 3: Interview-Style Questions
1. "How would you detect outliers in a dataset?"
2. "Explain the bias-variance tradeoff mathematically."
3. "When would you use median instead of mean?"

---

## Final Tips for the Interview

### Common Pitfalls to Avoid:
- ‚ùå Confusing correlation with causation
- ‚ùå Ignoring assumptions of statistical tests
- ‚ùå Forgetting to mention practical significance
- ‚ùå Not explaining the intuition behind formulas

### What Interviewers Look For:
- ‚úÖ Clear mathematical reasoning
- ‚úÖ Understanding of assumptions and limitations
- ‚úÖ Practical application knowledge
- ‚úÖ Ability to explain complex concepts simply

### Time Management:
- üìä **33.33% weightage** for this section
- ‚è±Ô∏è **30 minutes** allocated
- üéØ Aim for 2-3 detailed solutions + multiple quick concepts
- üìù Show your work clearly and systematically